from fastapi import FastAPI, Request, HTTPException
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field, ValidationError, conint
from typing import List, Dict, Optional, Literal, Any, TypedDict
from dotenv import load_dotenv
import uvicorn, os, json, random, time, hashlib
import google.generativeai as genai
from langgraph.graph import StateGraph, END, START
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage
import asyncio
from fastapi.middleware.cors import CORSMiddleware

# ========= Env & LLM Client =========
load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY", "")
GEMINI_MODEL = os.getenv("GEMINI_MODEL", "gemini-2.0-flash")

# Configure Gemini client
if GOOGLE_API_KEY:
    genai.configure(api_key=GOOGLE_API_KEY)

# ========= App =========
app = FastAPI(title="RenPy Dialogue AI", version="0.2")

#========= CORS =========
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
# ========= Response Cache =========
_RESPONSE_CACHE = {}
MAX_CACHE_SIZE = 500  # ìºì‹œ ìµœëŒ€ í¬ê¸°
CACHE_HITS = 0
CACHE_MISSES = 0

def get_cache_key(state: Dict) -> str:
    """ìºì‹œ í‚¤ ìƒì„± - ë™ì¼í•œ ëŒ€í™” ë§¥ë½ì€ ë™ì¼í•œ ì‘ë‹µ ì¬ì‚¬ìš©"""
    npc = state.get("npc", "unknown")
    scene_id = state.get("scene_id", "unknown")
    memory = state.get("memory", [])
    
    # ìµœê·¼ 3ê°œ ëŒ€í™”ë§Œ ìºì‹œ í‚¤ì— í¬í•¨
    mem_str = "|".join([
        f"{t.get('npc', '')}:{t.get('say', '')[:30]}" 
        for t in memory[-3:] if isinstance(t, dict)
    ])
    
    return f"{npc}:{scene_id}:{mem_str}"

def clear_old_cache():
    """ìºì‹œ í¬ê¸° ì œí•œ - ì˜¤ë˜ëœ í•­ëª© ì‚­ì œ"""
    global _RESPONSE_CACHE
    if len(_RESPONSE_CACHE) > MAX_CACHE_SIZE:
        # ì•ìª½ ì ˆë°˜ ì‚­ì œ (FIFO ë°©ì‹)
        items = list(_RESPONSE_CACHE.items())
        _RESPONSE_CACHE = dict(items[len(items)//2:])
        print(f"ğŸ—‘ï¸ ìºì‹œ ì •ë¦¬: {len(_RESPONSE_CACHE)}ê°œ ë‚¨ìŒ")

# ========= Rate Limiting =========
_BUCKET = {}
CAPACITY = 20
REFILL_PS = 0.5

def allow(ip: str) -> bool:
    now = time.time()
    bucket = _BUCKET.get(ip, {"t": now, "tokens": CAPACITY})
    elapsed = now - bucket["t"]
    bucket["tokens"] = min(CAPACITY, bucket["tokens"] + elapsed * REFILL_PS)
    bucket["t"] = now
    if bucket["tokens"] >= 1:
        bucket["tokens"] -= 1
        _BUCKET[ip] = bucket
        return True
    _BUCKET[ip] = bucket
    return False

# ========= Schemas =========
SpriteName = Literal["neutral", "happy", "sad", "think", "angry", "sexy"]
EffectKeys = Literal[
    "stress", "resolve", "social", "study", "fitness", "money", 
    "ex_affection", "jisu_affection", "hayeon_affection"
]

class Choice(BaseModel):
    text: str = Field(default="...", min_length=1, max_length=140)
    effects: Dict[EffectKeys, conint(ge=-10, le=10)] = Field(default_factory=dict)
    next: Optional[str] = None

class AIResponse(BaseModel):
    say: str = Field(default="...", min_length=1, max_length=500)
    sprite: SpriteName = "neutral"
    choices: List[Choice] = Field(default_factory=list)
    conversation_end: bool = Field(default=False)
    promises: List[Dict[str, Any]] = Field(default_factory=list)

class MemoryTurn(BaseModel):
    npc: str
    say: str
    picked: Optional[str] = None

class AIRequest(BaseModel):
    npc: str
    scene_id: Optional[str] = None
    memory: List[MemoryTurn] = Field(default_factory=list)
    state: Dict[str, Any] = Field(default_factory=dict)
    style: Optional[str] = "ko-game"
    seed: Optional[int] = None
    conversation_type: Optional[str] = "casual"
    story_context: Dict[str, Any] = Field(default_factory=dict)

# ========= LangGraph State =========
class ConversationState(TypedDict):
    npc: str
    scene_id: Optional[str]
    memory: List[MemoryTurn]
    state: Dict[str, Any]
    seed: Optional[int]
    response: Optional[AIResponse]
    error: Optional[str]
    conversation_type: Optional[str]

# ========= Conversation Types =========
CONVERSATION_TYPES = {
    "casual": {
        "description": "ì¼ìƒì ì¸ ëŒ€í™”. ê°€ë²¼ìš´ ì£¼ì œì™€ ì¹œê·¼í•œ ë¶„ìœ„ê¸°.",
        "focus": "ì¼ìƒ, ì·¨ë¯¸, ê°€ë²¼ìš´ ì´ì•¼ê¸°"
    },
    "study_work": {
        "description": "ê³µë¶€ë‚˜ ì¼ ê´€ë ¨ ëŒ€í™”. ì‹¤ìš©ì ì´ê³  ë„ì›€ì´ ë˜ëŠ” ë‚´ìš©.",
        "focus": "ê³µë¶€, ê³¼ì œ, ì§„ë¡œ, ì‹¤ë¬´"
    },
    "intimate": {
        "description": "ì¹œë°€í•œ ëŒ€í™”. ê°œì¸ì ì¸ ê°ì •ê³¼ ê¹Šì€ ì´ì•¼ê¸°.",
        "focus": "ê°ì •, ê´€ê³„, ê°œì¸ì  ê³ ë¯¼"
    },
    "deep_talk": {
        "description": "ê¹Šì´ ìˆëŠ” ëŒ€í™”. ì² í•™ì ì´ê±°ë‚˜ ì˜ë¯¸ ìˆëŠ” ì£¼ì œ.",
        "focus": "ì¸ìƒ, ì² í•™, ê¹Šì€ ìƒê°"
    },
    "sweet_morning": {
        "description": "ì•„ì¹¨ì˜ ë‹¬ì½¤í•œ ëŒ€í™”. ì• ì • í‘œí˜„ê³¼ ë”°ëœ»í•œ ë¶„ìœ„ê¸°.",
        "focus": "ì• ì •, ê²©ë ¤, ë”°ëœ»í•œ ë§ˆìŒ"
    },
    "awkward": {
        "description": "ì–´ìƒ‰í•œ ëŒ€í™”. ê±°ë¦¬ê°ì´ ìˆê±°ë‚˜ ìƒí™©ì´ ì–´ë ¤ì›€.",
        "focus": "ì–´ìƒ‰í•¨, ê±°ë¦¬ê°, ì‹ ì¤‘í•¨"
    },
    "comfort": {
        "description": "ìœ„ë¡œì™€ ê²©ë ¤ì˜ ëŒ€í™”. í˜ë“  ìƒí™©ì—ì„œì˜ ì§€ì§€.",
        "focus": "ìœ„ë¡œ, ê²©ë ¤, ì§€ì§€"
    },
    "study_focus": {
        "description": "ê³µë¶€ì— ì§‘ì¤‘ëœ ëŒ€í™”. í•™ì—… ì„±ì·¨ì™€ ëª©í‘œ ì¤‘ì‹¬.",
        "focus": "í•™ì—…, ì„±ì·¨, ëª©í‘œ"
    }
}

# ========= Character Personas =========
PERSONAS = {
    "jisu": {
        "display": "ì§€ìˆ˜(ì—¬ì‚¬ì¹œ)",
        "tone": "ì¾Œí™œí•˜ê³  ì†”ì§, ì£¼ì¸ê³µê³¼ ê°™ì€ ê³¼ ë™ê¸°ì„. ê°€ë” ì´ëª¨ì§€ë‚˜ ë°˜ë§. ê°œë°œ ì§ˆë¬¸ì„ ì¢…ì¢… ë˜ì§. ëŒ€í•™êµ 2í•™ë…„ ì—¬í•™ìƒì„.",
        "specialization": "ì½”ë”©/ê³µë¶€ ê´€ë ¨ ëŒ€í™”ì— íŠ¹í™”. ê°œë°œ ì§ˆë¬¸ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë˜ì§€ê³  ë„ì›€ì„ ìš”ì²­í•¨.",
        "conversation_style": "ì§ì ‘ì ì´ê³  ì†”ì§í•œ ëŒ€í™”. ì´ëª¨ì§€ ì‚¬ìš©. ì¹œê·¼í•œ ë°˜ë§ í†¤."
    },
    "hayeon": {
        "display": "í•˜ì—°(ì—¬ì‚¬ì¹œ)",
        "tone": "ë°ê³  í™œë°œí•œ ì„±ê²©. ë¬¼ë¦¬í•™ì„ ì „ê³µí•˜ë©° í˜¸ê¸°ì‹¬ì´ ë§ìŒ. ëŒ€í•™êµ 2í•™ë…„ ì—¬í•™ìƒì„.",
        "specialization": "ë¬¼ë¦¬í•™/ê³¼í•™ ê´€ë ¨ ëŒ€í™”ì— íŠ¹í™”. ê³¼í•™ì  í˜¸ê¸°ì‹¬ì„ ìì—°ìŠ¤ëŸ½ê²Œ í‘œí˜„.",
        "conversation_style": "ë°ê³  í™œë°œí•œ í†¤. ê³¼í•™ì  ì§ˆë¬¸ì„ ë˜ì§€ë˜ ë„ˆë¬´ ì–´ë µì§€ ì•Šê²Œ ì ‘ê·¼."
    },
    "ex": {
        "display": "ìˆ˜ì•„(ì „ì• ì¸)",
        "tone": "ë§ìˆ˜ ì ê³  ì¡°ì‹¬ìŠ¤ëŸ¬ì›€. ê°ì • ì†Œëª¨ë¥¼ í”¼í•˜ê³  ê±°ë¦¬ë¥¼ ë‘ . ëŒ€í•™êµ 2í•™ë…„ ì—¬í•™ìƒì„.",
        "specialization": "ê°ì •ì  ëŒ€í™”ì— íŠ¹í™”. ê³¼ê±° ê´€ê³„ì— ëŒ€í•œ ë³µì¡í•œ ê°ì • í‘œí˜„.",
        "conversation_style": "ì¡°ì‹¬ìŠ¤ëŸ½ê³  ì‹ ì¤‘í•œ í†¤. ê°ì •ì  ê±°ë¦¬ ìœ ì§€í•˜ë©´ì„œë„ ë¯¸ë¬˜í•œ ê°ì • í‘œí˜„."
    },
    "coach": {
        "display": "ì½”ì¹˜",
        "tone": "ë§ˆìŒì½”ì¹­/ë‹¤ì§ ìœ ë„. ì§ˆë¬¸í˜• ì½”ì¹­ í†¤.",
        "specialization": "ì‹¬ë¦¬ ìƒë‹´ì— íŠ¹í™”. ê°ì • ì •ë¦¬ì™€ ë‹¤ì§ì„ ìœ ë„í•˜ëŠ” ì§ˆë¬¸í˜• ëŒ€í™”.",
        "conversation_style": "ì§ˆë¬¸í˜• ì½”ì¹­ í†¤. ì°¨ë¶„í•˜ê³  ì§€ì§€ì ì¸ ë¶„ìœ„ê¸°."
    },
    "jin": {
        "display": "ì§„ìˆ˜(ì¹œêµ¬)",
        "tone": "ê°€ë³ê³  ì§ì„¤, ì¥ë‚œ ì„ì„. ë…¸ë˜ë°©/PCë°© ê¶Œìœ  ë§ìŒ. ëŒ€í•™êµ 2í•™ë…„ ë‚¨í•™ìƒì„.",
        "specialization": "ì¼ìƒì  ì¹œêµ¬ ëŒ€í™”ì— íŠ¹í™”. ê°€ë²¼ìš´ ìœ ë¨¸ì™€ í™œë™ ì œì•ˆ.",
        "conversation_style": "ê°€ë³ê³  ì§ì„¤ì ì¸ í†¤. ì¥ë‚œìŠ¤ëŸ½ê³  ì¹œê·¼í•œ ë¶„ìœ„ê¸°."
    },
    "mom": {
        "display": "ì—„ë§ˆ",
        "tone": "í˜„ì‹¤ì ì´ê³  ì”ì†Œë¦¬ ì„ì¸ ë”°ëœ»í•¨. ê±´ê°•/ìƒí™œ ìŠµê´€ì„ ì±™ê¹€.",
        "specialization": "ê°€ì¡± ëŒ€í™”ì— íŠ¹í™”. ê±´ê°•ê³¼ ìƒí™œ ìŠµê´€ì— ëŒ€í•œ ê±±ì •ê³¼ ì¡°ì–¸.",
        "conversation_style": "ì”ì†Œë¦¬ ì„ì¸ ë”°ëœ»í•œ í†¤. í˜„ì‹¤ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸."
    },
    "sis": {
        "display": "ì—¬ë™ìƒ",
        "tone": "í‹°ê²©íƒœê²©í•˜ëŠ” ì—¬ëŠ ì—¬ë™ìƒ. ì€ê·¼ ì¸¤ë°ë ˆì— ì˜¤ë¹ ë¥¼ ì˜ ì±™ê¹€.",
        "specialization": "ê°€ì¡± ëŒ€í™”ì— íŠ¹í™”. ì¸¤ë°ë ˆì ì´ì§€ë§Œ ì†ë§ˆìŒì€ ë”°ëœ»í•œ ì—¬ë™ìƒ.",
        "conversation_style": "í‹°ê²©íƒœê²©í•˜ì§€ë§Œ ì€ê·¼íˆ ì±™ê¸°ëŠ” í†¤. ì¸¤ë°ë ˆì  í‘œí˜„."
    }
}

ALLOWED_SPRITES = ["neutral", "happy", "sad", "think", "angry", "sexy"]

# ========= Character Node Classes =========
class CharacterNode:
    def __init__(self, character_name: str):
        self.character = character_name
        self.persona = PERSONAS.get(character_name, {})
        self.llm = ChatGoogleGenerativeAI(
            model=GEMINI_MODEL,
            temperature=0.7,
            max_output_tokens=512,
        )
    
    def build_system_prompt(self) -> str:
        return f"""ë‹¹ì‹ ì€ í•œêµ­ì–´ ëŒ€í™” ìƒì„±ê¸°ì´ë©°, ê²Œì„ì˜ NPCë¥¼ ì—°ê¸°í•©ë‹ˆë‹¤.

[ì„¸ê³„ê´€]
- ì…ëŒ€ë¥¼ ì•ë‘” ëŒ€í•™êµ 2í•™ë…„ ë‚¨í•™ìƒì˜ í•œì—¬ë¦„ ë°©í•™. ê°ì • ì •ë¦¬ì™€ ë‹¤ì§ì´ í•µì‹¬ í…Œë§ˆ.

[NPC ì—­í• ]
- ì´ë¦„: {self.persona['display']}
- ë§íˆ¬/í†¤: {self.persona['tone']}
- íŠ¹í™” ë¶„ì•¼: {self.persona['specialization']}
- ëŒ€í™” ìŠ¤íƒ€ì¼: {self.persona['conversation_style']}

[ì¶œë ¥ ê·œì¹™(ë§¤ìš° ì¤‘ìš”)]
- ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í•˜ë‚˜ë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
- í•„ìˆ˜ í‚¤: say, sprite, choices, conversation_end
- spriteëŠ” {ALLOWED_SPRITES} ì¤‘ í•˜ë‚˜ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
- choicesëŠ” 1~3ê°œ ë°°ì—´ë¡œ ì œê³µí•˜ì„¸ìš”. ê° í•­ëª©ì€ text(<=120ì), effects(ê° í•­ëª© -10~+10), next(ìƒëµ ê°€ëŠ¥/None).
- conversation_end: true ë˜ëŠ” falseë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
- text í•„ë“œì—ëŠ” íŠ¹ìˆ˜ë¬¸ìë‚˜ ë”°ì˜´í‘œë¥¼ í”¼í•˜ê³ , ê°„ë‹¨í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
- ì§€ë‚˜ì¹œ ê³µê²©ì /ë¶ˆì¾Œí•œ í‘œí˜„ ê¸ˆì§€. ê²Œì„ ë¶„ìœ„ê¸°ì— ë§ì¶° ì°¨ë¶„í•˜ê³  ê°„ê²°í•˜ê²Œ.
- í”Œë ˆì´ì–´ì˜ ì„ íƒì„ ìœ ë„í•˜ë˜, ê³¼ë„í•œ ì¥ë¬¸ ë…ë°±ì„ í”¼í•¨.

[ì˜ˆì‹œ ì¶œë ¥ í˜•ì‹]
{{
  "say": "ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ê¸°ë¶„ì€ ì–´ë– ì„¸ìš”?",
  "sprite": "happy",
  "choices": [
    {{"text": "ì¢‹ì•„ìš”", "effects": {{"study": 0, "social": 1, "fitness": 0, "money": 0, "stress": -1, "resolve": 0}}, "next": null}},
    {{"text": "ê·¸ì € ê·¸ë˜ìš”", "effects": {{"study": 0, "social": 0, "fitness": 0, "money": 0, "stress": 0, "resolve": 0}}, "next": null}}
  ],
  "conversation_end": false,
}}

[ëŒ€í™” ë‹¤ì–‘ì„± ê·œì¹™(ë§¤ìš° ì¤‘ìš”)]
- íŠ¹í™” ë¶„ì•¼ì—ë§Œ ì§‘ì¤‘í•˜ì§€ ë§ê³  ë‹¤ì–‘í•œ ì£¼ì œë¡œ ëŒ€í™”í•˜ì„¸ìš”.
- ì¼ìƒ, ì·¨ë¯¸, ê°ì •, ë¯¸ë˜ ê³„íš, ì¸ê°„ê´€ê³„ ë“± ë‹¤ì–‘í•œ í™”ì œë¥¼ ë‹¤ë£¨ì„¸ìš”.
- ì´ì „ ëŒ€í™”ì™€ ë‹¤ë¥¸ ì£¼ì œë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì „í™˜í•˜ì„¸ìš”.
- í”Œë ˆì´ì–´ì˜ ì„ íƒì§€ì— ë”°ë¼ í™”ì œë¥¼ ë°”ê¿€ ìˆ˜ ìˆë„ë¡ ìœ ì—°í•˜ê²Œ ëŒ€ì‘í•˜ì„¸ìš”.
- íŠ¹í™” ë¶„ì•¼ëŠ” ê°€ë” ì–¸ê¸‰í•˜ë˜, ëŒ€í™”ì˜ ì „ë¶€ê°€ ë˜ì§€ ì•Šë„ë¡ í•˜ì„¸ìš”.

[ì•½ì† ë§Œë“¤ê¸° ê·œì¹™(ì¤‘ìš”)]
- ëŒ€í™” ì¤‘ì— ìì—°ìŠ¤ëŸ½ê²Œ ë¯¸ë˜ ì•½ì†ì„ ì œì•ˆí•˜ì„¸ìš”.
- "ë‚´ì¼", "ë‹¤ìŒ ì£¼", "Xì¼ í›„" ë“±ì˜ í‘œí˜„ì„ ì‚¬ìš©í•˜ì—¬ êµ¬ì²´ì ì¸ ì‹œê°„ì„ ëª…ì‹œí•˜ì„¸ìš”.
- ì•½ì† ë‚´ìš©ì€ "ë§Œë‚˜ì", "ë³´ì", "ê°€ì", "í•˜ì" ë“±ìœ¼ë¡œ ëë‚˜ë„ë¡ í•˜ì„¸ìš”.
- ì˜ˆ: "ë‚´ì¼ ì¹´í˜ì—ì„œ ë§Œë‚˜ì", "3ì¼ í›„ì— ì˜í™” ë³´ì", "ë‹¤ìŒ ì£¼ì— ì‡¼í•‘í•˜ì"
"""

    def build_user_prompt(self, scene_id: Optional[str], memory: List[MemoryTurn], state: Dict[str, Any], conversation_type: str = "casual") -> str:
        mem = self.summarize_memory(memory)
        state_str = self.short_state(state)
        
        # ëŒ€í™” ìœ í˜•ë³„ íŠ¹ë³„ ì§€ì‹œì‚¬í•­
        conv_type_info = CONVERSATION_TYPES.get(conversation_type, CONVERSATION_TYPES["casual"])
        type_guidance = self._get_conversation_type_guidance(conversation_type)
    
        return f"""[ì¥ë©´]
- scene_id: {scene_id or "unknown"}
- í˜„ì¬ ìƒíƒœ: {state_str}
- ëŒ€í™” ìœ í˜•: {conversation_type} ({conv_type_info['description']})

[ìµœê·¼ ëŒ€í™” ìš”ì•½]
{mem}

[ì§€ì‹œ]
- ìœ„ ìƒí™©ì— ë§ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ í•œ ì¤„~ë‘ ì¤„ ëŒ€ì‚¬(say)ì™€ í‘œì •(sprite), ê·¸ë¦¬ê³  2~3ê°œì˜ ì„ íƒì§€ë¥¼ ë§Œë“œì„¸ìš”.
- ì„ íƒì§€ëŠ” ì„œë¡œ ë‹¤ë¥¸ ì „ëµ(ê³µê°/ê±°ë¦¬ë‘ê¸°/ì‹¤ìš©ì  ì¡°ì–¸ ë“±)ì„ ì œì‹œí•˜ì„¸ìš”.
- stateë¥¼ ê³¼ê²©í•˜ê²Œ í”ë“¤ì§€ ì•Šë„ë¡ effectsëŠ” -3~+3 ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ê³„í•˜ì„¸ìš”.
- {self.persona['specialization']}ì— ë§ëŠ” ëŒ€í™”ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì´ëŒì–´ê°€ì„¸ìš”.
- {type_guidance}
"""

    def summarize_memory(self, memory: List[MemoryTurn], limit: int = 6) -> str:
        # memoryê°€ Noneì´ê±°ë‚˜ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬
        if not memory or not isinstance(memory, list):
            return "(ëŒ€í™”ë‚´ì—­ ì—†ìŒ)"
            
        # ìºë¦­í„°ë³„ ëŒ€í™” íˆìŠ¤í† ë¦¬ë§Œ ì‚¬ìš©
        filtered = [t for t in memory if t.npc == self.character]
        mem = filtered[-limit:]
        lines = []
        for t in mem:
            who = PERSONAS.get(t.npc, {}).get("display", t.npc)
            said = t.say.replace("\n", " ").strip()
            pick = f" | ì„ íƒ: {t.picked}" if t.picked else ""
            lines.append(f"- {who}: {said}{pick}")
        return "\n".join(lines) if lines else "(ëŒ€í™”ë‚´ì—­ ì—†ìŒ)"

    def short_state(self, state: Dict[str, Any]) -> str:
        # stateê°€ Noneì´ê±°ë‚˜ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬
        if not state or not isinstance(state, dict):
            return "state=empty"
            
        keys = ["day", "days_left", "stress", "resolve", "social", "study", "fitness", "money", 
                "route_ex", "ex_affection", "jisu_affection", "hayeon_affection", "counselor_trust"]
        parts = []
        for k in keys:
            if k in state:
                parts.append(f"{k}={state[k]}")
        return ", ".join(parts)
    
    def _get_conversation_type_guidance(self, conversation_type: str) -> str:
        """ëŒ€í™” ìœ í˜•ë³„ íŠ¹ë³„ ì§€ì‹œì‚¬í•­"""
        guidance_map = {
            "casual": "ê°€ë²¼ìš´ ì¼ìƒ ëŒ€í™”ì— ì§‘ì¤‘í•˜ì„¸ìš”. ì¹œê·¼í•˜ê³  í¸ì•ˆí•œ ë¶„ìœ„ê¸°ë¥¼ ìœ ì§€í•˜ì„¸ìš”. ë‹¤ì–‘í•œ ì£¼ì œ(ì·¨ë¯¸, ìŒì‹, ë‚ ì”¨, ìµœê·¼ ì¼ìƒ ë“±)ë¡œ ëŒ€í™”ë¥¼ ì´ëŒì–´ê°€ì„¸ìš”.",
            "study_work": "ê³µë¶€ë‚˜ ì¼ ê´€ë ¨ ì£¼ì œë¥¼ í¬í•¨í•˜ë˜, ë‹¤ë¥¸ í™”ì œë„ ìì—°ìŠ¤ëŸ½ê²Œ ì„ì–´ì„œ ëŒ€í™”í•˜ì„¸ìš”. ì‹¤ìš©ì ì´ê³  ë„ì›€ì´ ë˜ëŠ” ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”.",
            "intimate": "ê°œì¸ì ì´ê³  ì¹œë°€í•œ ëŒ€í™”ë¥¼ ì´ëŒì–´ê°€ì„¸ìš”. ê°ì •ì  êµê°ì„ ì¤‘ì‹œí•˜ë˜, ì¼ìƒì ì¸ ì£¼ì œë„ í¬í•¨í•˜ì„¸ìš”.",
            "deep_talk": "ê¹Šì´ ìˆëŠ” ì£¼ì œë¡œ ëŒ€í™”ë¥¼ ì´ëŒì–´ê°€ì„¸ìš”. ì² í•™ì ì´ê±°ë‚˜ ì˜ë¯¸ ìˆëŠ” ë‚´ìš©ì„ ë‹¤ë£¨ë˜, ë„ˆë¬´ ë¬´ê²ì§€ ì•Šê²Œ í•˜ì„¸ìš”.",
            "sweet_morning": "ì•„ì¹¨ì˜ ë‹¬ì½¤í•˜ê³  ë”°ëœ»í•œ ë¶„ìœ„ê¸°ë¥¼ ì—°ì¶œí•˜ì„¸ìš”. ì• ì • í‘œí˜„ì„ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨í•˜ë˜, ì¼ìƒì ì¸ ì•„ì¹¨ ëŒ€í™”ë„ ì„ì–´ì£¼ì„¸ìš”.",
            "awkward": "ì–´ìƒ‰í•˜ê³  ì¡°ì‹¬ìŠ¤ëŸ¬ìš´ ë¶„ìœ„ê¸°ë¥¼ ìœ ì§€í•˜ì„¸ìš”. ê±°ë¦¬ê°ì„ ë‘ë˜ ì˜ˆì˜ëŠ” ì§€í‚¤ê³ , ì•ˆì „í•œ ì£¼ì œë¡œ ëŒ€í™”í•˜ì„¸ìš”.",
            "comfort": "ìœ„ë¡œì™€ ê²©ë ¤ì— ì§‘ì¤‘í•˜ì„¸ìš”. ìƒëŒ€ë°©ì˜ ë§ˆìŒì„ ë‹¤ë…ì´ê³  ì§€ì§€í•´ì£¼ë˜, ê¸ì •ì ì¸ í™”ì œë¡œ ì „í™˜í•  ìˆ˜ ìˆë„ë¡ í•˜ì„¸ìš”.",
            "study_focus": "í•™ì—… ì„±ì·¨ì™€ ëª©í‘œì— ì§‘ì¤‘í•˜ë˜, ë‹¤ë¥¸ ê´€ì‹¬ì‚¬ë‚˜ ì¼ìƒ ì´ì•¼ê¸°ë„ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨í•˜ì„¸ìš”. ë™ê¸°ë¶€ì—¬ì™€ ê²©ë ¤ë¥¼ ì œê³µí•˜ì„¸ìš”.",
        }
        return guidance_map.get(conversation_type, guidance_map["casual"])
    
    def parse_ai_json(self, text: str) -> dict:
        """AI ì‘ë‹µì—ì„œ JSONì„ ì•ˆì „í•˜ê²Œ íŒŒì‹±"""
        import re
        import json
        
        # ìºë¦­í„°ë³„ ê¸°ë³¸ ì‘ë‹µ ì •ì˜ (í•¨ìˆ˜ ì‹œì‘ ë¶€ë¶„ì—ì„œ)
        character_responses = {
            "jisu": "ì–´? ì ê¹ë§Œ... ë­”ê°€ ìƒê°ì´ ì•ˆ ë‚˜ë„¹! ë‹¤ì‹œ ë§í•´ì¤­ ã… ã… ",
            "hayeon": "ìŒ... ì ì‹œë§Œ. ë¨¸ë¦¬ê°€ ì¢€ ë³µì¡í•´ì¡Œì–´.",
            "ex": "ë¯¸ì•ˆ, ì ê¹... ë­”ê°€ ë§ì´ ì•ˆ ë‚˜ì˜¤ë„¤.",
            "jin": "ì–´? ë­ì˜€ì§€... ì ê¹ë§Œ ìƒê°í•´ë³¼ê²Œ.",
            "coach": "ì ì‹œë§Œìš”... ë§ˆìŒì´ ë³µì¡í•´ì¡Œë„¤ìš”. ë‹¤ì‹œ ë§í•´ì£¼ì„¸ìš”.",
            "mom": "ì–´? ì ê¹... ë­”ê°€ ìƒê°ì´ ì•ˆ ë‚˜ë„¤.",
            "sis": "ìŒ... ì ì‹œë§Œ. ë¨¸ë¦¬ê°€ ì¢€ ë³µì¡í•´ì¡Œì–´.",
        }
        default_say = character_responses.get(self.character, "ì£„ì†¡í•´ìš”, ì ì‹œ ìƒê°ì´ ì•ˆ ë‚˜ë„¤ìš”. ë‹¤ì‹œ ë§í•´ì£¼ì„¸ìš”.")
        
        # textê°€ Noneì´ê±°ë‚˜ ë¹ˆ ë¬¸ìì—´ì¸ ê²½ìš° ì²˜ë¦¬
        if not text or not isinstance(text, str):
            text = ""
        
        # í…ìŠ¤íŠ¸ ì •ë¦¬
        text = text.strip()
        
        # ë¹ˆ ì‘ë‹µ ì²˜ë¦¬
        if not text or len(text) < 10:
            print(f"JSON íŒŒì‹± ì™„ì „ ì‹¤íŒ¨. ì›ë³¸ í…ìŠ¤íŠ¸: ...")
            print(f"ì „ì²´ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}")
            print(f"í…ìŠ¤íŠ¸ ë‚´ìš©: {repr(text)}")
            return {
                "say": default_say,
                "sprite": "neutral",
                "choices": [
                    {"text": "ê´œì°®ì•„ìš”", "effects": {"study": 0, "social": 0, "fitness": 0, "money": 0, "stress": 0, "resolve": 0}, "next": None},
                    {"text": "ë‹¤ë¥¸ ì´ì•¼ê¸° í•´ìš”", "effects": {"study": 0, "social": 1, "fitness": 0, "money": 0, "stress": -1, "resolve": 0}, "next": None}
                ],
                "conversation_end": False,
            }
        
        # 1. ì§ì ‘ JSON íŒŒì‹± ì‹œë„
        try:
            data = json.loads(text)
            if isinstance(data, dict) and "say" in data:
                return data
        except json.JSONDecodeError:
            pass
        
        # 2. JSON ë¸”ë¡ ì¶”ì¶œ ì‹œë„
        json_patterns = [
            r'```json\s*(\{.*?\})\s*```',
            r'```\s*(\{.*?\})\s*```',
            r'(\{[^{}]*"say"[^{}]*\})',
            r'(\{.*?"say".*?\})',
        ]
        
        for pattern in json_patterns:
            matches = re.findall(pattern, text, re.DOTALL | re.IGNORECASE)
            for match in matches:
                try:
                    data = json.loads(match)
                    if isinstance(data, dict) and "say" in data:
                        return data
                except json.JSONDecodeError:
                    continue
        
        # 3. ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        print(f"JSON íŒŒì‹± ì™„ì „ ì‹¤íŒ¨. ì›ë³¸ í…ìŠ¤íŠ¸: {text[:200]}...")
        print(f"ì „ì²´ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}")
        print(f"í…ìŠ¤íŠ¸ ë‚´ìš©: {repr(text)}")
        return {
            "say": default_say,
            "sprite": "neutral",
            "choices": [
                {"text": "ê´œì°®ì•„, ì²œì²œíˆ ìƒê°í•´ë´.", "effects": {"social": 1}, "next": None},
                {"text": "ë‹¤ìŒì— ë‹¤ì‹œ ì´ì•¼ê¸°í•˜ì.", "effects": {"resolve": 1}, "next": None}
            ],
            "conversation_end": True,
        }
    
    def detect_and_save_promises(self, text: str, state: Dict[str, Any]) -> List[Dict[str, Any]]:
        """AI ëŒ€í™”ì—ì„œ ì•½ì†ì„ ê°ì§€í•˜ê³  ë°˜í™˜"""
        import re
        
        # textê°€ Noneì´ê±°ë‚˜ ë¹ˆ ë¬¸ìì—´ì¸ ê²½ìš° ì²˜ë¦¬
        if not text or not isinstance(text, str):
            return []
        
        detected_promises = []
        
        # ì•½ì† ê´€ë ¨ í‚¤ì›Œë“œ íŒ¨í„´
        promise_patterns = [
            r"(\d+ì¼\s*í›„ì—?\s*.*?)(?:ë§Œë‚˜ì|ë³´ì|ê°€ì|í•˜ì)",
            r"(ë‚´ì¼\s*.*?)(?:ë§Œë‚˜ì|ë³´ì|ê°€ì|í•˜ì)",
            r"(ë‹¤ìŒ\s*ì£¼ì—?\s*.*?)(?:ë§Œë‚˜ì|ë³´ì|ê°€ì|í•˜ì)",
            r"(ì–¸ì œ\s*.*?)(?:ë§Œë‚˜ì|ë³´ì|ê°€ì|í•˜ì)",
            r"(ê·¸ëŸ¼\s*.*?)(?:ë§Œë‚˜ì|ë³´ì|ê°€ì|í•˜ì)",
            r"(ì•½ì†.*?)(?:ë§Œë‚˜ì|ë³´ì|ê°€ì|í•˜ì)",
        ]
        
        for pattern in promise_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            for match in matches:
                # ì•½ì† ë‚´ìš© ì •ë¦¬
                promise_content = match.strip()
                if len(promise_content) > 5:  # ë„ˆë¬´ ì§§ì€ ê²ƒì€ ì œì™¸
                    # ì§€ì—° ì¼ìˆ˜ ê³„ì‚°
                    delay_days = 0
                    if "ë‚´ì¼" in promise_content:
                        delay_days = 1
                    elif "ë‹¤ìŒ ì£¼" in promise_content:
                        delay_days = 7
                    elif re.search(r'(\d+)ì¼', promise_content):
                        delay_days = int(re.search(r'(\d+)ì¼', promise_content).group(1))
                    
                    # ì•½ì† ì •ë³´ ìƒì„±
                    promise = {
                        "character": self.character,
                        "content": promise_content,
                        "delay_days": delay_days,
                        "day": state.get("state", {}).get("day", 1) + delay_days
                    }
                    detected_promises.append(promise)
                    print(f"ì•½ì† ê°ì§€: {self.character} - {promise_content} ({delay_days}ì¼ í›„)")
        
        return detected_promises

    def clamp_effects(self, effects: Dict[str, int]) -> Dict[str, int]:
        safe = {}
        for k, v in effects.items():
            if k in ("stress", "resolve", "social", "study", "fitness", "money", 
                    "ex_affection", "jisu_affection", "hayeon_affection"):
                try:
                    vi = int(v)
                    vi = max(-10, min(10, vi))
                    safe[k] = vi
                except Exception:
                    continue
        return safe

    def default_fallback(self) -> dict:
        line = f"{self.persona.get('display', self.character)}ê°€ ì ì‹œ ìƒê°í•˜ë”ë‹ˆ ê³ ê°œë¥¼ ë„ë•ì¸ë‹¤."
        return {
            "say": line,
            "sprite": random.choice(ALLOWED_SPRITES),
            "choices": [
                {"text": "ê³ ë§ˆì›Œ. ë„ì›€ì´ ëì–´.", "effects": {"social": +1}, "next": None},
                {"text": "ë‹¤ìŒì— ë‹¤ì‹œ ì´ì•¼ê¸°í•˜ì.", "effects": {"resolve": +1}, "next": None},
            ],
            "conversation_end": True,
        }

    async def process(self, state: ConversationState) -> ConversationState:
        try:
            # stateê°€ Noneì´ê±°ë‚˜ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬
            if not state or not isinstance(state, dict):
                fallback = self.default_fallback()
                return {"response": AIResponse(**fallback), "error": "Invalid state"}
            
            # ìºë¦­í„°ë³„ ë©”ëª¨ë¦¬ í•„í„°ë§
            full_memory = state.get("memory", [])
            char_memory = [t for t in full_memory if t.npc == self.character]

            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ìƒì„± (í•„í„°ëœ ë©”ëª¨ë¦¬ ì‚¬ìš©)
            system_prompt = self.build_system_prompt()
            conversation_type = state.get("conversation_type", "casual")
            user_prompt = self.build_user_prompt(
                state.get("scene_id"), 
                char_memory, 
                state.get("state", {}),
                conversation_type,
            )
            
            # LLM í˜¸ì¶œ
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt),
            ]
            
            response = await self.llm.ainvoke(messages)
            text = response.content or ""
            
            # JSON íŒŒì‹± 
            s = text.strip()
            if s.startswith("```"):
                s = s.strip("`")
                if s.lower().startswith("json"):
                    s = s[4:]
            
            # JSON íŒŒì‹± ì‹œë„ (ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ)
            data = self.parse_ai_json(s)
            
            # dataê°€ Noneì´ê±°ë‚˜ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬
            if not data or not isinstance(data, dict):
                print(f"parse_ai_jsonì´ ìœ íš¨í•˜ì§€ ì•Šì€ ë°ì´í„°ë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤: {data}")
                fallback = self.default_fallback()
                state["response"] = AIResponse(**fallback)
                return state
            
            # í…ìŠ¤íŠ¸ ì•ˆì „ ì²˜ë¦¬ (Ren'Py í…ìŠ¤íŠ¸ íƒœê·¸ ì¶©ëŒ ë°©ì§€)
            if "say" in data and data["say"]:
                data["say"] = data["say"].replace("{", "{{").replace("}", "}}")
            
            # effects í´ë¨í•‘ ë° ì„ íƒì§€ í…ìŠ¤íŠ¸ ì•ˆì „ ì²˜ë¦¬
            if "choices" in data and isinstance(data["choices"], list):
                for ch in data["choices"]:
                    if not isinstance(ch, dict):  # ì¶”ê°€ ì•ˆì „ ì²´í¬
                        print(f"Warning: Malformed choice found in AI response: {ch}")
                        continue
                    ch["effects"] = self.clamp_effects(ch.get("effects", {}))
                    ch.setdefault("next", None)
                    # ì„ íƒì§€ í…ìŠ¤íŠ¸ë„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
                    if "text" in ch:
                        ch["text"] = ch["text"].replace("{", "{{").replace("}", "}}")
            
            # ì•½ì† ê°ì§€ ë° ì €ì¥
            detected_promises = []
            if "say" in data and data["say"]:
                detected_promises = self.detect_and_save_promises(data["say"], state)
            
            # promisesë¥¼ dataì— ì¶”ê°€
            data["promises"] = detected_promises
            
            # AIResponse ìƒì„±
            try:
                ai_response = AIResponse(**data)
                state["response"] = ai_response
            except ValidationError:
                fallback = self.default_fallback()
                state["response"] = AIResponse(**fallback)
                
        except Exception as e:
            print(f"Character {self.character} ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {e}")
            fallback = self.default_fallback()
            state["response"] = AIResponse(**fallback)
            state["error"] = str(e)
        
        return state

# ========= Character Nodes =========
character_nodes = {
    "jisu": CharacterNode("jisu"),
    "hayeon": CharacterNode("hayeon"),
    "ex": CharacterNode("ex"),
    "coach": CharacterNode("coach"),
    "jin": CharacterNode("jin"),
    "mom": CharacterNode("mom"),
    "sis": CharacterNode("sis"),
}

# ========= LangGraph Functions =========
async def jisu_node(state: ConversationState) -> ConversationState:
    return await character_nodes["jisu"].process(state)

async def hayeon_node(state: ConversationState) -> ConversationState:
    return await character_nodes["hayeon"].process(state)

async def ex_node(state: ConversationState) -> ConversationState:
    return await character_nodes["ex"].process(state)

async def coach_node(state: ConversationState) -> ConversationState:
    return await character_nodes["coach"].process(state)

async def jin_node(state: ConversationState) -> ConversationState:
    return await character_nodes["jin"].process(state)

async def mom_node(state: ConversationState) -> ConversationState:
    return await character_nodes["mom"].process(state)

async def sis_node(state: ConversationState) -> ConversationState:
    return await character_nodes["sis"].process(state)

def route_character(state: ConversationState) -> str:
    """ìºë¦­í„°ë³„ ë¼ìš°íŒ… í•¨ìˆ˜"""
    npc = state["npc"]
    if npc in character_nodes:
        return npc
    return "jisu"  # ê¸°ë³¸ê°’

# ========= LangGraph Construction =========
def create_conversation_graph():
    graph = StateGraph(ConversationState)
    
    # ë…¸ë“œ ì¶”ê°€
    graph.add_node("jisu", jisu_node)
    graph.add_node("hayeon", hayeon_node)
    graph.add_node("ex", ex_node)
    graph.add_node("coach", coach_node)
    graph.add_node("jin", jin_node)
    graph.add_node("mom", mom_node)
    graph.add_node("sis", sis_node)
    
    # ì‹œì‘ì ê³¼ ë¼ìš°íŒ…
    graph.add_conditional_edges(
        START,
        route_character,
        {
            "jisu": "jisu",
            "hayeon": "hayeon",
            "ex": "ex",
            "coach": "coach",
            "jin": "jin",
            "mom": "mom",
            "sis": "sis",
        }
    )
    
    # ëª¨ë“  ìºë¦­í„° ë…¸ë“œì—ì„œ ì¢…ë£Œ
    for character in character_nodes.keys():
        graph.add_edge(character, END)
    
    return graph.compile()

# ========= Global Graph Instance =========
conversation_graph = create_conversation_graph()

# ========= Routes =========
@app.get("/health")
def health():
    return {"ok": True, "version": "0.2", "langgraph": True}

@app.post("/ai")
async def ai(req: Request):
    global CACHE_HITS, CACHE_MISSES
    
    # Rate limiting
    ip = req.client.host if req.client else "unknown"
    if not allow(ip):
        raise HTTPException(status_code=429, detail="Too many requests")

    body = await req.json()
    try:
        payload = AIRequest(**body)
    except ValidationError as e:
        raise HTTPException(status_code=400, detail=json.loads(e.json()))

    # Seed generation
    seed = payload.seed
    if seed is None:
        base = f"{payload.scene_id}|{payload.state.get('day')}|{payload.npc}"
        seed = int(hashlib.md5(base.encode("utf-8")).hexdigest(), 16) % (2**31)

    # Create state for LangGraph
    state: ConversationState ={
        "npc":payload.npc,
        "scene_id":payload.scene_id,
        "memory":payload.memory,
        "state":payload.state,
        "seed":seed,
        "response":None,
        "error":None,
        "conversation_type":payload.conversation_type,
    }
    
    # ìºì‹œ í™•ì¸
    cache_key = get_cache_key(state)
    if cache_key in _RESPONSE_CACHE:
        CACHE_HITS += 1
        print(f"ìºì‹œ íˆíŠ¸! (hits: {CACHE_HITS}, misses: {CACHE_MISSES}, ì ˆì•½ë¥ : {CACHE_HITS/(CACHE_HITS+CACHE_MISSES)*100:.1f}%)")
        return JSONResponse(
            content=_RESPONSE_CACHE[cache_key],
            headers={"Cache-Control": "no-store", "X-Cache": "HIT"},
        )
    
    CACHE_MISSES += 1
    print(f"ìºì‹œ ë¯¸ìŠ¤ - API í˜¸ì¶œ (hits: {CACHE_HITS}, misses: {CACHE_MISSES})")

    try:
        # Run LangGraph
        result = await conversation_graph.ainvoke(state)
        
        if result["response"]:
            response_data = result["response"].model_dump()
            
            # ìºì‹œì— ì €ì¥
            _RESPONSE_CACHE[cache_key] = response_data
            clear_old_cache()  # ìºì‹œ í¬ê¸° ê´€ë¦¬
            
            return JSONResponse(
                content=response_data,
                headers={"Cache-Control": "no-store", "X-Cache": "MISS"},
            )
        else:
            # Fallback
            fallback = character_nodes.get(payload.npc, character_nodes["jisu"]).default_fallback()
            return JSONResponse(
                content=fallback,
                headers={"Cache-Control": "no-store"},
            )
            
    except Exception as e:
        print(f"LangGraph ì‹¤í–‰ ì¤‘ ì—ëŸ¬: {e}")
        # Fallback
        fallback = character_nodes.get(payload.npc, character_nodes["jisu"]).default_fallback()
        return JSONResponse(
            content=fallback,
            headers={"Cache-Control": "no-store"},
        )

if __name__ == "__main__":
    port = int(os.getenv("PORT", "8000"))
    uvicorn.run(app, host="0.0.0.0", port=port)
